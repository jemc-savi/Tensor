:module _FFI.DataType(T Numeric(T)'val)
  :fun code I32
    // These values must be kept in sync with include/tensorflow/c/tf_datatype.h
    case T <: (
    | F32 | 1
    | F64 | 2
    | I32 | 3  // Int32 tensors are always in 'host' memory.
    | U8  | 4
    | I16 | 5
    | I8  | 6
    // | TF_STRING | 7    // TODO: How to handle this in Savi?
    // | TF_COMPLEX64 | 8 // Single-precision complex
    // | TF_COMPLEX | 8   // Old identifier kept for API backwards compatibility
    | I64 | 9
    | Bool | 10
    // | TF_QINT8 | 11     // Quantized int8
    // | TF_QUINT8 | 12    // Quantized uint8
    // | TF_QINT32 | 13    // Quantized int32
    // | TF_BFLOAT16 | 14  // Float32 truncated to 16 bits.  Only for cast ops.
    // | TF_QINT16 | 15    // Quantized int16
    // | TF_QUINT16 | 16   // Quantized uint16
    | U16 | 17
    // | TF_COMPLEX128 | 18  // Double-precision complex
    // | TF_HALF | 19
    // | TF_RESOURCE | 20
    // | TF_VARIANT | 21
    | U32 | 22
    | U64 | 23
    |
      // TODO: What is a reasonable thing to do in this fall-through case?
      // In theory someone could supply a home-built numeric type
      // that was an oddball size, and we'd likely have some unsafe
      // stuff happen as a result of not having a right number to map to.
      -1
    )

:module _FFI.DataType.Util
  :fun non _tensor_with_type(
    type_code I32
    ptr CPointer(_FFI.Tensor)
    ptr_is_owned Bool
  ) Tensor.Any
    // These values must be kept in sync with include/tensorflow/c/tf_datatype.h
    case type_code == (
    | 1  | Tensor(F32)._new(ptr, ptr_is_owned)
    | 2  | Tensor(F64)._new(ptr, ptr_is_owned)
    | 3  | Tensor(I32)._new(ptr, ptr_is_owned)
    | 4  | Tensor(U8)._new(ptr, ptr_is_owned)
    | 5  | Tensor(I16)._new(ptr, ptr_is_owned)
    | 6  | Tensor(I8)._new(ptr, ptr_is_owned)
    | 9  | Tensor(I64)._new(ptr, ptr_is_owned)
    | 10 | Tensor(Bool)._new(ptr, ptr_is_owned)
    | 17 | Tensor(U16)._new(ptr, ptr_is_owned)
    | 22 | Tensor(U32)._new(ptr, ptr_is_owned)
    | 23 | Tensor(U64)._new(ptr, ptr_is_owned)
    |
      // TODO: What is a reasonable thing to do in this fall-through case?
      if ptr_is_owned _FFI.Tensor.free(ptr)
      Tensor(Bool).from_array([False])
    )
